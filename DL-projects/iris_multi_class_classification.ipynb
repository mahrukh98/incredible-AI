{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris-multi-class-classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wFqbA-UlBfeF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multi-Class Classification Iris Flowers Project 2 for Mothers who love Gardening and Flowers: Identifying Flower Types\n"
      ]
    },
    {
      "metadata": {
        "id": "0FmKmjCr_kUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3dfe873b-921b-4158-8612-caf89c70e406"
      },
      "cell_type": "code",
      "source": [
        "# All necessary imports here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3_z3ZevYDLl_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-1pWGyXGVIv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1. Project Description\n",
        "The Iris dataset consists of 50 samples, each of 3 different speciecs of Iris flower, in total 150 samples with 4 input variables namely: sepal length, sepal width, petal length and petal width. While, 3 output variables as the name of species: Iris-setosa, Iris-versicolor and Iris-virginica."
      ]
    },
    {
      "metadata": {
        "id": "Ri9YkI1CGzYB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2. Making Preparations"
      ]
    },
    {
      "metadata": {
        "id": "0odnJKKiDTmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "path_to_data = \"https://raw.githubusercontent.com/mahrukh98/incredible-AI/master/datasets/iris.csv\"\n",
        "dataframe = pd.read_csv(path_to_data, header = None)\n",
        "dataset = dataframe.values\n",
        "\n",
        "# splitting into input(X) and output(Y) variables\n",
        "X = dataset[:,0:4].astype(float)\n",
        "Y = dataset[:,4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sYyVeYIqFGVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "604c0eba-1f8f-4cd5-d295-f775863a95c5"
      },
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "OGxOCBPefHWc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As the output variables need to be numerical so as to be predicted by the model, we're using the Label Encoder class from scikit-learn, then fit_transform method to learn the labels' mean and standard deviation afterwards applying those transformations on the training dataset for encoded labels. The resulting numerical values are then one-hot encoded."
      ]
    },
    {
      "metadata": {
        "id": "AYggI6MlFGe7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoded_Y = encoder.fit_transform(Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sPHftPEqgCru",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, we've received the encoded variables where [1,0,0] represents Iris-setosa, [0,1,0] represents Iris-versicolor and [0,0,1] represents Iris-virginica!"
      ]
    },
    {
      "metadata": {
        "id": "oYtEy5SQGIUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2745
        },
        "outputId": "93365885-7bb6-418a-df71-c2988b8d866c"
      },
      "cell_type": "code",
      "source": [
        "dummy_y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "n1WIaXkqHRBS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3: Define the Neural Network Baseline Model\n",
        "Creating the baseline model with single, densely connected hidden layer of 8 hidden units and randomly initialized weights. The hidden layer is passed through 'relu' activation function that zeroes-out the negative values and only keeps the positive values of computation. Output layer with 3 units is passed through 'softmax' activation function to give the ouput values in between  0 and 1 as probabilities, where the higher value represents the higher class.\n",
        "Finally, 'categorical_crossentropy' loss function which is particular for the multi-class classification problems , 'Adam' optimizer along with recording accuracy metrics are reserved for compilation."
      ]
    },
    {
      "metadata": {
        "id": "jtXncNmVGL44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "  # create model\n",
        "  model = Sequential([\n",
        "    Dense(8, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(3),\n",
        "    Activation('softmax'),\n",
        "   ])\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P5W8jTAjLEgg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TPnOQIoSODEz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4. Evaluate The Model with k-Fold Cross Validation"
      ]
    },
    {
      "metadata": {
        "id": "5g8khviCrGYp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, evaluating the model using k-fold cross-validation in the scikit-learn framework for that purpose we're using KerasClassifier wrapper class with the model creation function, number of epochs and batch_size as argument."
      ]
    },
    {
      "metadata": {
        "id": "8_djkW56OR1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "c895bc41-7409-4dcf-deb0-e428a48dbdb5"
      },
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Baseline model's accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Baseline model's accuracy: 97.33% (4.42%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bKCaRWHiOxkW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5. Tuning Layers and Number of Neurons in The Model\n",
        "\n",
        "### Step 5.1. Evaluate a Smaller Network\n",
        "Observing what reducing the hidden units to 4 gives us! \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WbryY-GAOwLH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define smaller model\n",
        "def smaller_model():\n",
        "  # create model\n",
        "  model = Sequential([\n",
        "    Dense(4, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(3),\n",
        "    Activation('softmax'),\n",
        "   ])\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WIaL9aMLQf7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "13bb956a-1ccd-4b21-9832-98bf0d99e100"
      },
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=smaller_model, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Smaller model's accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smaller model's accuracy: 98.00% (3.06%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zd928clbrhcl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Woah! That's pretty awesome!! 98.00% We need to continue or improve this! :D "
      ]
    },
    {
      "metadata": {
        "id": "UCySmPruPQ0R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Step 5.2. Evaluate a Larger Network\n",
        "Just checking, if increasing another layer results in good performance or not. Here, we're using 2 hidden layers, first one with 8 hidden units and the second one with 4 hidden units!\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9qeFAn0cPX70",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define larger model\n",
        "def larger_model():\n",
        "  # create model\n",
        "  model = Sequential([\n",
        "    Dense(8, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(4, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(3),\n",
        "    Activation('softmax'),\n",
        "   ])\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ygUWXwFHRMHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cd824d3-1cd2-422d-a64d-8dda4cfe6915"
      },
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=larger_model, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Larger model's accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Larger model's accuracy: 84.00% (23.32%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9PPlPrtbPYpi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 6. Really Scaling up: developing a model that overfits\n",
        "Now, to figure out the strength of our model that it lies exactly right at the border between the underfitting and overfitting, we'll have to cross that border i.e. overfit the model. This can be achieved by:\n",
        "\n",
        "\n",
        "1.   Adding layers ----- 3 layers + 1 output layer\n",
        "2.   Increasing hidden units --- 16-----> 8 ------> 4 ------>3\n",
        "3.   Training for more epochs ---250\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "E3ZtAAPwR_Ju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define overfitting model\n",
        "def overfitting_model():\n",
        "  # create model\n",
        "  model = Sequential([\n",
        "    Dense(16, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(8, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(4, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(3),\n",
        "    Activation('softmax'),\n",
        "   ])\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gfgQirYAW_cB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3c5fbd6-c7e5-4ef9-9cd8-66e2128f8cfc"
      },
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=overfitting_model, epochs=250, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Overfitted model's accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overfitted model's accuracy: 85.33% (26.63%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rU1KODTN2jIY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Seems the model is underfitting and even of the worse kind, if we compare it with previously achieved 98%!"
      ]
    },
    {
      "metadata": {
        "id": "GlFxUdjKR_pw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 7. Tuning the Model"
      ]
    },
    {
      "metadata": {
        "id": "s-3cuAnE3DhP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Trying the 'rmsprop' optimizer instead of 'Adam', but seeems this model got inclined with the baseline model's performance."
      ]
    },
    {
      "metadata": {
        "id": "80OkcNe4SCYL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define improved model\n",
        "def improved_model():\n",
        "  # create model\n",
        "  model = Sequential([\n",
        "    Dense(4, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(3),\n",
        "    Activation('softmax'),\n",
        "   ])\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TGwtZil1dzUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "03c9f942-b905-4f5c-bb17-8997c44e117a"
      },
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=improved_model, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Improved model's accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Improved model's accuracy: 97.33% (4.42%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h1aIPLQgEUok",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll continue with this model onwards!"
      ]
    },
    {
      "metadata": {
        "id": "bwN63lQnSCwk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 8. Rewriting the code using the Keras Functional API"
      ]
    },
    {
      "metadata": {
        "id": "bGfRuQeOSLjJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MaWrc6kz6qVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9d861bfa-84dc-4240-9187-403bdfdec14c"
      },
      "cell_type": "code",
      "source": [
        "# creating functional API for improved model \n",
        "def create_improved_fn():\n",
        "  inputs = keras.Input(shape = (4,))\n",
        "  x = layers.Dense(4, activation='relu')(inputs)\n",
        "  output = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "  model = keras.Model(inputs, output)\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=create_improved_fn, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Improved model's accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Improved model's accuracy: 97.33% (4.42%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GiBjIQG1SSFF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 9. Rewriting the code by doing Model Subclassing"
      ]
    },
    {
      "metadata": {
        "id": "vaZWbApaSNuD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68cafb51-2511-4d44-bf32-3f55ed178efc"
      },
      "cell_type": "code",
      "source": [
        "# Creating subclass for improved model\n",
        "class Improved(keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Improved, self).__init__()\n",
        "    self.dense1 = layers.Dense(4, activation='relu')\n",
        "    self.dense2 = layers.Dense(3, activation='softmax')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    return self.dense2(x)\n",
        "  \n",
        "# DISCLAIMER!!!\n",
        "# This part is inspired from the functional API style :D \n",
        "# As, build_fn needs callable function or class instance, we're generating another method which will also accompany the input shape not specified in the class and \n",
        "# compilation step\n",
        "\n",
        "def create_Improved_subclass():\n",
        "  inputs = keras.Input(shape = (4,))\n",
        "  model = Improved()\n",
        "  output = model.call(inputs)\n",
        "  \n",
        "  model = keras.Model(inputs, output)\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=create_Improved_subclass, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Improved model's accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Improved model's accuracy: 97.33% (3.27%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6SfCiLcUSU61",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 10. Rewriting the code without using scikit-learn\n",
        "Here, we're asked for selecting the best model and implementing its code + the k-fold cross validation without scikit-learn !"
      ]
    },
    {
      "metadata": {
        "id": "QiZn0nc7SUKc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define improved model\n",
        "def improved_model():\n",
        "  # create model\n",
        "  model = Sequential([\n",
        "    Dense(4, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(3),\n",
        "    Activation('softmax'),\n",
        "   ])\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mfFpxHoQB6VY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "36c6934a-711b-4c67-d48d-8b065da35ba6"
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(seed)\n",
        "k = 10\n",
        "num_val_samples = len(dataset) // k\n",
        "np.random.shuffle(dataset)\n",
        "all_scores = []\n",
        "num_epochs = 200\n",
        "\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "\n",
        "  # Preparing the validation data and properly partitioning training data\n",
        "  val_X = X[num_val_samples * i:num_val_samples * (i + 1)]\n",
        "  train_X = np.append(X[:num_val_samples * i], X[num_val_samples * (i + 1):], axis=0) \n",
        "    \n",
        "  val_Y = dummy_y[num_val_samples * i:num_val_samples * (i + 1)]\n",
        "  train_Y = np.append(dummy_y[:num_val_samples * i] , dummy_y[num_val_samples * (i + 1):], axis=0)\n",
        "  # Building the Keras model (already compiled)\n",
        "  model = improved_model() \n",
        "  all_scores = model.fit(train_X,train_Y,epochs=num_epochs,batch_size=5,verbose=0,validation_data = (val_X,val_Y))\n",
        "  \n",
        "  # Saving state dictionary of model    \n",
        "  history_dict = all_scores.history\n",
        "  val_score = np.average(history_dict['val_acc'])\n",
        "\n",
        "  print(\"Final improved model's accuracy: %.2f%% \" % (val_score*100))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Final improved model's accuracy: 96.80% \n",
            "processing fold # 1\n",
            "Final improved model's accuracy: 92.80% \n",
            "processing fold # 2\n",
            "Final improved model's accuracy: 100.00% \n",
            "processing fold # 3\n",
            "Final improved model's accuracy: 82.97% \n",
            "processing fold # 4\n",
            "Final improved model's accuracy: 66.10% \n",
            "processing fold # 5\n",
            "Final improved model's accuracy: 42.23% \n",
            "processing fold # 6\n",
            "Final improved model's accuracy: 86.17% \n",
            "processing fold # 7\n",
            "Final improved model's accuracy: 100.00% \n",
            "processing fold # 8\n",
            "Final improved model's accuracy: 87.63% \n",
            "processing fold # 9\n",
            "Final improved model's accuracy: 75.30% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PLUsR97eC-un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eecf4d7d-b901-4448-f017-adf16c67313e"
      },
      "cell_type": "code",
      "source": [
        "print(\"Final improved model's accuracy: mean =  %.2f%% and standard deviation = %.2f%% \" % (val_score.mean()*100, val_score.std()*100))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final improved model's accuracy: mean =  75.30% and standard deviation = 0.00% \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}